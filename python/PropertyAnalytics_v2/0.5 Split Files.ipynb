{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import calendar\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union  # ← this line is essential!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\\\dtuklaptop\\\\e\\\\Users\\\\Mat\\python\\\\data\\\\property\\\\bank-download\\\\'\n",
    "generated_path = 'E:\\\\dtuklaptop\\\\e\\\\Users\\\\Mat\\\\python\\\\data\\\\property\\\\generated\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_transactions_by_month(\n",
    "    input_csv: Union[str, Path],\n",
    "    output_dir: Optional[Union[str, Path]] = None,\n",
    "    account_prefix_override: Optional[str] = None,\n",
    "    encoding: str = \"utf-8\",\n",
    "    verbose: bool = True,\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    Read a CSV with columns:\n",
    "      Number, Date, Account, Amount, Subcategory, Memo\n",
    "    where Date is in UK format (dd/MM/YYYY). Split by (year, month),\n",
    "    sort ascending by date, and write CSVs named:\n",
    "      BC_XXXX_MONYYYY.csv\n",
    "    \"\"\"\n",
    "\n",
    "    input_csv = Path(input_csv)\n",
    "    if output_dir is None:\n",
    "        output_dir = input_csv.parent\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Read CSV; keep Account as string so leading zeros are preserved\n",
    "    df = pd.read_csv(input_csv, dtype={\"Account\": str}, encoding=encoding)\n",
    "\n",
    "    # Normalize column names\n",
    "    df.columns = [c.strip().title() for c in df.columns]\n",
    "    required = [\"Number\", \"Date\", \"Account\", \"Amount\", \"Subcategory\", \"Memo\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\"Missing required columns: {}\".format(missing))\n",
    "\n",
    "    # Parse UK-style dates and sort ascending\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "    if df[\"Date\"].isna().any():\n",
    "        bad = df[df[\"Date\"].isna()][[\"Date\"]]\n",
    "        raise ValueError(\n",
    "            \"Some Date values could not be parsed with dd/MM/YYYY. \"\n",
    "            \"Offending rows:\\n{}\".format(bad.head().to_string(index=False))\n",
    "        )\n",
    "\n",
    "    df = df.sort_values(\"Date\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # Extract 4-digit account prefix\n",
    "    def get_prefix(acc):\n",
    "        digits = re.sub(r\"\\D\", \"\", str(acc))\n",
    "        if len(digits) < 4:\n",
    "            raise ValueError(\"Account '{}' doesn’t contain 4 digits.\".format(acc))\n",
    "        return digits[:4]\n",
    "\n",
    "    if account_prefix_override:\n",
    "        acct_prefix = account_prefix_override\n",
    "        df[\"_AcctPrefix\"] = acct_prefix\n",
    "    else:\n",
    "        df[\"_AcctPrefix\"] = df[\"Account\"].apply(get_prefix)\n",
    "\n",
    "    df[\"_Year\"] = df[\"Date\"].dt.year\n",
    "    df[\"_MonthNum\"] = df[\"Date\"].dt.month\n",
    "    df[\"_MonthAbbr\"] = df[\"_MonthNum\"].apply(lambda m: calendar.month_abbr[m].upper())\n",
    "\n",
    "    written_paths = []\n",
    "    for (acct4, year, mon_abbr), g in df.groupby([\"_AcctPrefix\", \"_Year\", \"_MonthAbbr\"]):\n",
    "        out_name = \"BC_{}_{}{}.csv\".format(acct4, mon_abbr, year)\n",
    "        out_path = output_dir / out_name\n",
    "        g = g.sort_values(\"Date\")\n",
    "        g[[\"Number\", \"Date\", \"Account\", \"Amount\", \"Subcategory\", \"Memo\"]].to_csv(\n",
    "            out_path, index=False, date_format=\"%d/%m/%Y\"\n",
    "        )\n",
    "        written_paths.append(out_path)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Wrote {} file(s) to '{}'\".format(len(written_paths), output_dir))\n",
    "\n",
    "    return written_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import calendar\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "EXPECTED_COLS = [\"Number\", \"Date\", \"Account\", \"Amount\", \"Subcategory\", \"Memo\"]\n",
    "\n",
    "def _robust_read_csv(path, encoding=\"utf-8\"):\n",
    "    \"\"\"\n",
    "    Read a 'mostly CSV' file where some rows may have extra commas.\n",
    "    Any extra fields beyond the first 5 are joined back into Memo.\n",
    "    Preserves header if present; otherwise treats all rows as data.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=encoding, newline=\"\") as f:\n",
    "        reader = csv.reader(f)  # handles quotes if they exist\n",
    "        try:\n",
    "            header = next(reader)\n",
    "        except StopIteration:\n",
    "            return pd.DataFrame(columns=EXPECTED_COLS)\n",
    "\n",
    "        # Normalize header and decide if it's a real header\n",
    "        header_norm = [str(h).strip().title() for h in header]\n",
    "        has_header = header_norm == EXPECTED_COLS\n",
    "\n",
    "        if not has_header:\n",
    "            # First row is actually data → process it\n",
    "            data_row = header\n",
    "            if len(data_row) < 6:\n",
    "                data_row += [\"\"] * (6 - len(data_row))\n",
    "            elif len(data_row) > 6:\n",
    "                fixed = data_row[:5]\n",
    "                memo = \",\".join(data_row[5:])\n",
    "                data_row = fixed + [memo]\n",
    "            rows.append(data_row)\n",
    "\n",
    "        for row in reader:\n",
    "            if not row or all((c is None or str(c).strip() == \"\") for c in row):\n",
    "                continue\n",
    "            if len(row) < 6:\n",
    "                row += [\"\"] * (6 - len(row))\n",
    "            elif len(row) > 6:\n",
    "                fixed = row[:5]\n",
    "                memo = \",\".join(row[5:])\n",
    "                row = fixed + [memo]\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=EXPECTED_COLS)\n",
    "    # Normalize column names just in case\n",
    "    df.columns = [c.strip().title() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def split_transactions_by_month(\n",
    "    input_csv: Union[str, Path],\n",
    "    output_dir: Optional[Union[str, Path]] = None,\n",
    "    account_prefix_override: Optional[str] = None,\n",
    "    encoding: str = \"utf-8\",\n",
    "    verbose: bool = True,\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    Read a CSV with columns:\n",
    "      Number, Date, Account, Amount, Subcategory, Memo\n",
    "    where Date is UK format (dd/MM/YYYY). Split by year+month, sort by date asc,\n",
    "    and write CSVs named: BC_XXXX_MONYYYY.csv\n",
    "    \"\"\"\n",
    "    input_csv = Path(input_csv)\n",
    "    output_dir = Path(output_dir) if output_dir else input_csv.parent\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # First attempt: normal pandas read (fast)\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            input_csv,\n",
    "            dtype={\"Account\": str},\n",
    "            encoding=encoding,\n",
    "            engine=\"c\",\n",
    "        )\n",
    "        df.columns = [c.strip().title() for c in df.columns]\n",
    "        # Validate expected columns quickly; otherwise fall back\n",
    "        if any(col not in df.columns for col in EXPECTED_COLS):\n",
    "            raise ValueError(\"Missing required columns in header; trying robust read…\")\n",
    "    except Exception:\n",
    "        # Fallback: tolerant parser that stitches extra commas back into Memo\n",
    "        df = _robust_read_csv(str(input_csv), encoding=encoding)\n",
    "\n",
    "    # Final column check\n",
    "    missing = [c for c in EXPECTED_COLS if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\"Missing required columns after parsing: {}\".format(missing))\n",
    "\n",
    "    # Parse UK dates and sort\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "    if df[\"Date\"].isna().any():\n",
    "        bad = df[df[\"Date\"].isna()][[\"Number\", \"Date\", \"Account\"]].head()\n",
    "        raise ValueError(\n",
    "            \"Some Date values could not be parsed as dd/MM/YYYY. \"\n",
    "            \"Example bad rows:\\n{}\".format(bad.to_string(index=False))\n",
    "        )\n",
    "    df = df.sort_values(\"Date\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # Extract 4-digit account prefix\n",
    "    def get_prefix(acc):\n",
    "        \"\"\"\n",
    "        Extract first four digits of the *account number* from strings like:\n",
    "          \"11-22-33 44445555\"  -> \"4444\"\n",
    "          \"11 22 33   01234567\"-> \"0123\"\n",
    "          \"Sort: 12-34-56 Acc: 98765432\" -> \"9876\"\n",
    "        Strategy: find the last contiguous run of digits in the string; require ≥4 digits.\n",
    "        \"\"\"\n",
    "        s = \"\" if acc is None else str(acc)\n",
    "        # Find all digit runs; pick the last one (expected to be the account number)\n",
    "        m = list(re.finditer(r\"\\d+\", s))\n",
    "        if not m:\n",
    "            raise ValueError(\"Account '{}' contains no digits.\".format(acc))\n",
    "        last_run = m[-1].group(0)\n",
    "        if len(last_run) < 4:\n",
    "            raise ValueError(\"Account '{}' does not have ≥4 digits in the account number.\".format(acc))\n",
    "        return last_run[:4]\n",
    "\n",
    "    written_paths = []\n",
    "    # Group by account prefix + year + month abbreviation\n",
    "    for (acct4, year, mon_abbr), g in df.groupby([\"_AcctPrefix\", \"_Year\", \"_MonthAbbr\"]):\n",
    "        out_name = \"BC_{}_{}{}.csv\".format(acct4, mon_abbr, year)\n",
    "        out_path = output_dir / out_name\n",
    "        g = g.sort_values(\"Date\")\n",
    "        g[EXPECTED_COLS].to_csv(out_path, index=False, date_format=\"%d/%m/%Y\")\n",
    "        written_paths.append(out_path)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Wrote {} file(s) to '{}'\".format(len(written_paths), output_dir))\n",
    "    return written_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import calendar\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "# Expected column order for output\n",
    "EXPECTED_COLS = [\"Number\", \"Date\", \"Account\", \"Amount\", \"Subcategory\", \"Memo\"]\n",
    "\n",
    "def _robust_read_csv(path, encoding=\"utf-8\"):\n",
    "    \"\"\"\n",
    "    Read a 'mostly CSV' file where some rows may contain extra commas (typically in Memo).\n",
    "    Any extra fields beyond the first 5 are joined back into Memo.\n",
    "    Preserves header if present; otherwise treats all rows as data.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=encoding, newline=\"\") as f:\n",
    "        reader = csv.reader(f)  # handles quotes properly if present\n",
    "        try:\n",
    "            header = next(reader)\n",
    "        except StopIteration:\n",
    "            return pd.DataFrame(columns=EXPECTED_COLS)\n",
    "\n",
    "        # Normalize header and decide if it's a real header\n",
    "        header_norm = [str(h).strip().title() for h in header]\n",
    "        has_header = header_norm == EXPECTED_COLS\n",
    "\n",
    "        if not has_header:\n",
    "            # First row is actually data → process it into 6 fields\n",
    "            data_row = header\n",
    "            if len(data_row) < 6:\n",
    "                data_row += [\"\"] * (6 - len(data_row))\n",
    "            elif len(data_row) > 6:\n",
    "                fixed = data_row[:5]\n",
    "                memo = \",\".join(data_row[5:])\n",
    "                data_row = fixed + [memo]\n",
    "            rows.append(data_row)\n",
    "\n",
    "        for row in reader:\n",
    "            # Skip completely empty rows\n",
    "            if not row or all((c is None or str(c).strip() == \"\") for c in row):\n",
    "                continue\n",
    "            # Normalize to exactly 6 fields\n",
    "            if len(row) < 6:\n",
    "                row += [\"\"] * (6 - len(row))\n",
    "            elif len(row) > 6:\n",
    "                fixed = row[:5]\n",
    "                memo = \",\".join(row[5:])\n",
    "                row = fixed + [memo]\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=EXPECTED_COLS)\n",
    "    df.columns = [c.strip().title() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def get_prefix(acc):\n",
    "    \"\"\"\n",
    "    Extract the first four digits of the *account number* from strings like:\n",
    "      \"11-22-33 44445555\"      -> \"4444\"\n",
    "      \"11 22 33   01234567\"    -> \"0123\"\n",
    "      \"Sort: 12-34-56 Acc: 98765432\" -> \"9876\"\n",
    "    Strategy: find the *last* contiguous run of digits (account number) and take its first 4.\n",
    "    \"\"\"\n",
    "    s = \"\" if acc is None else str(acc)\n",
    "    matches = list(re.finditer(r\"\\d+\", s))\n",
    "    if not matches:\n",
    "        raise ValueError(\"Account '{}' contains no digits.\".format(acc))\n",
    "    account_digits = matches[-1].group(0)  # last run of digits = account number\n",
    "    if len(account_digits) < 4:\n",
    "        raise ValueError(\"Account '{}' does not have ≥4 digits in the account number.\".format(acc))\n",
    "    return account_digits[:4]\n",
    "\n",
    "def split_transactions_by_month(\n",
    "    input_csv: Union[str, Path],\n",
    "    output_dir: Optional[Union[str, Path]] = None,\n",
    "    account_prefix_override: Optional[str] = None,\n",
    "    encoding: str = \"utf-8\",\n",
    "    verbose: bool = True,\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    Read a CSV with columns:\n",
    "      Number, Date, Account, Amount, Subcategory, Memo\n",
    "    where Date is in UK format (dd/MM/YYYY). Split by (year, month), sort by\n",
    "    ascending date, and write CSVs named:\n",
    "      BC_XXXX_MONYYYY.csv\n",
    "\n",
    "    - XXXX: first four digits of the *account number* (last digit-run in Account field)\n",
    "    - MON : three-letter month abbreviation in upper-case\n",
    "    - YYYY: four-digit year\n",
    "    \"\"\"\n",
    "    input_csv = Path(input_csv)\n",
    "    out_dir = Path(output_dir) if output_dir else input_csv.parent\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Fast path with pandas; 2) Fallback to robust reader on error\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv, dtype={\"Account\": str}, encoding=encoding, engine=\"c\")\n",
    "        df.columns = [c.strip().title() for c in df.columns]\n",
    "        if any(col not in df.columns for col in EXPECTED_COLS):\n",
    "            raise ValueError(\"Missing required columns in header; trying robust read…\")\n",
    "    except Exception:\n",
    "        df = _robust_read_csv(str(input_csv), encoding=encoding)\n",
    "\n",
    "    # Final column check\n",
    "    missing = [c for c in EXPECTED_COLS if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\"Missing required columns after parsing: {}\".format(missing))\n",
    "\n",
    "    # Parse UK dates strictly and sort ascending\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "    if df[\"Date\"].isna().any():\n",
    "        bad = df[df[\"Date\"].isna()][[\"Number\", \"Date\", \"Account\"]].head()\n",
    "        raise ValueError(\n",
    "            \"Some Date values could not be parsed as dd/MM/YYYY. \"\n",
    "            \"Example bad rows:\\n{}\".format(bad.to_string(index=False))\n",
    "        )\n",
    "    df = df.sort_values(\"Date\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # Determine 4-digit prefix\n",
    "    if account_prefix_override:\n",
    "        if not re.fullmatch(r\"\\d{4}\", str(account_prefix_override)):\n",
    "            raise ValueError(\"account_prefix_override must be exactly 4 digits.\")\n",
    "        df[\"_AcctPrefix\"] = str(account_prefix_override)\n",
    "    else:\n",
    "        df[\"_AcctPrefix\"] = df[\"Account\"].apply(get_prefix)\n",
    "\n",
    "    # Year/Month for grouping and filenames\n",
    "    df[\"_Year\"] = df[\"Date\"].dt.year\n",
    "    df[\"_MonthNum\"] = df[\"Date\"].dt.month\n",
    "\n",
    "    written_paths = []\n",
    "    # Group by account prefix + year + month number to guarantee chronological order\n",
    "    for (acct4, year, month_num), g in df.groupby([\"_AcctPrefix\", \"_Year\", \"_MonthNum\"], sort=True):\n",
    "        mon_abbr = calendar.month_abbr[int(month_num)].upper()\n",
    "        out_name = \"BC_{}_{}{}.csv\".format(acct4, mon_abbr, year)\n",
    "        out_path = out_dir / out_name\n",
    "\n",
    "        g = g.sort_values(\"Date\", ascending=True)\n",
    "        g[EXPECTED_COLS].to_csv(out_path, index=False, date_format=\"%d/%m/%Y\")\n",
    "        written_paths.append(out_path)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Wrote {} file(s) to '{}'\".format(len(written_paths), out_dir))\n",
    "    return written_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 10 file(s) to 'J:\\My Drive\\NAS\\My Documents\\Business\\Property\\Statements\\working\\python\\data\\property\\bank-download'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_JAN2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_FEB2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_MAR2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_APR2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_MAY2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_JUN2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_JUL2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_AUG2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_SEP2025.csv'),\n",
       " WindowsPath('J:/My Drive/NAS/My Documents/Business/Property/Statements/working/python/data/property/bank-download/BC_6045_OCT2025.csv')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = \"J://My Drive//NAS//My Documents//Business//Property//Statements//working//python//data//property//bank-download//6045_2025.csv\"\n",
    "split_transactions_by_month(\n",
    "    input_path,\n",
    "    output_dir=\"J://My Drive//NAS//My Documents//Business//Property//Statements//working//python//data//property//bank-download\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split big Barclays file by month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input file is just a download from Barclays:\n",
    "- output files are 'BC_XXXX_MMMYYYY.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
